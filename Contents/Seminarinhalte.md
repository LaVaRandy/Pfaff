# Seminarinhalte

Im Seminar wird viel "gemacht" und weniger gelehrt.
Dadurch kommt jede Teilnehmerin und jeder Teilnehmer mit einem gut gefüllten Koffer an neuen Werkzeugen und bereits implementierten Beispielen zurück.
Diese Beispiele können dannn in der Praxis unmittelbar eingesetzt werden.

Damit die unmittelbare Anwendbarkeit noch stärker in den Vordergrund rückt, kann das Seminar modular absolviert werden. Wir empfehlen, je nach Interesse und Bedarf, einen (oder mehrere) der drei Muster-Programme:

- **Grundlagen:** Alle Programme basieren auf Python und Jupyter Notebooks, bevor wir damit beginnen gibt es eine kurze Einführung in *Data Science*. Alle verwendeten Bibliotheken sind frei und *Open Source*, also im Unternehmenskontext ohne direkte Investition nutzbar.
- **Datenanalyse:** Sie wollen Daten aus ihrem Unternehmen und aus anderen Quellen integrieren? Sie wollen datenbasierte Abläufe automatisieren und in ihrer Organisation verteilt nutzbar machen? Dann lernen sie in diesem Programm die Daten zur erforschen, effiziente Datenhaltung (auch für Big Data geeignet) sowie Methoden der künstlichen Intelligenz kennen und können sie anwenden. Optional setzen sie das Erlernte in einer WebApp um, die sie unternehmensweit bereitstellen können.
- **Simulation:** Sie müssen spezialisierte Simulationen durchführen, evtl. bestehende Routinen fit für die Zukunft machen? In diesem Programme lernen sie, Aufgaben der numerischen Mathematik in Python umzusetzen, dynamische Systeme zu simulieren sowie Monte-Carlo- und Rare-Event Simulationen, zum Beispiel für Sicherheitsbetrachtungen, kennen und anwenden.
- **Bildverarbeitung:** Sie müssen visuelle Daten, zum Beispiel aus automatischen Inspektionsanlagen oder papierbasierten Prozessen, verarbeiten? Dieses Programm führt, basierend auf der numerischen Mathematik, in Bilderfassung und -verarbeitung ein, um sie dann Objekte und Texte automatisiert erfassen und verarbeiten zu lassen.

## Kurzbeschreibung der Module

### Datenanalyse

- **Datenstrukturen**: Ohne Datenstrukturen keine Algorithmen. In diesem Modul geht es um tabellenartige Datenstrukturen, die wir mit der Bibliothek *Pandas* nutzen.
- **Exploration und Visualisierung**: Wir importieren Daten aus lokalen und Cloud-Quellen, stellen sie graphisch dar und untersuchen mit effizienten Tools ihre Eigenschaften. Dazu setzen wir u.a. *Matplotlib*, *Seaborn* und *Plotly* ein.
- **KI-Methoden:** Künstliche Intelligenz ist in aller Munde. Wir nutzen *Scikit-Learn*, eine sehr zugängliche KI-Bibliothek um Methoden wie Clustering, Support-Vector-Machines und Autoencoder auszuprobieren.
- **WebApp:** Mit den richtigen Tools ist es leicht geworden, die zuvor entwickelten Lösungen nutzbar zu machen. In diesem Modul entwickeln wir eine erste WebApp mit *Flask* und zeigen den Weg in die Cloud.

### Simulation

- **Numerik**: Die Numerik-Bibliothek *NumPy* macht Berechnungen einfach und elegant. Wir setzen einige Beispiele um und lernen damit die Konzepte und Strukturen kennen.
- **Dynamische Systeme:** Oft müssen dynamische Systeme und regelungstechnische Strukturen simuliert werden. Wir nutzen *PyControl* für Simulationen linearer dynamischer Systeme und Reglereinstellung.
- **Monte-Carlo-Simulationen:** Viele Prozesse laufen zufällig ab. In diesem Modul lernen wir, den Zufall zu simulieren und damit Vorhersagen über das Ergebnis, zum Beispiel nach Änderung von Prozessvariablen, zu treffen.
- **Rare-Event-Simulation:** Zufallsprozesse mit seltenen Events kommen im System Bahn an vielen Stellen vor, beispielsweise bei Bremskurven. Die speziellen Ansätze für Rare-Event-Simulation werden wir in *NumPy* umsetzen.

### Bildverarbeitung

- **Numerik**: Die Numerik-Bibliothek *NumPy* macht Berechnungen einfach und elegant. Wir setzen einige Beispiele um und lernen damit die Konzepte und Strukturen kennen.
- **Bildverarbeitung:** In diesem Modul lernen wir, Bilddaten zu erfassen, grundlegende Transformationen durchzuführen und sie anzuzeigen und zu speichern. Dazu nutzen wir *OpenCV*, die Grundlage für viele Bildverarbeitungsaufgaben bis hin zu autonomem Fahren.
- **Objekterkennung:** Das Erfassen, Markieren, Zählen und Lokalisieren von Objekten in den Bilddaten gehört zu den grundlegenden Aufgaben, die wir hier mit analytischen Methoden und vortrainierten Filtern lösen.
- **Texterkennung:** Viele Prozesse in Unternehmen nutzen papiergebundene Formulare. In diesem Modul lesen wir Bilder dieser Dokumente ein und extrahieren die Texte von Interesse mit Hilfe von *PyTesseract*, um sie automatisiert nutzbar zu machen.