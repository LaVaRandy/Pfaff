{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing in OpenCV and Jupyter\n",
    "\n",
    "The image processing library OpenCV provides a very powerful Python interface, that we will explore in the sequel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV\n",
    "import cv2\n",
    "# Since OpenCV is based on numpy:\n",
    "import numpy as np\n",
    "# Import pyplot (we will need this to plot with the notebook)\n",
    "import matplotlib.pyplot as plt\n",
    "# Helper function to provide plots in true colors in the notebook\n",
    "def imshow(title, im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and display of images\n",
    "\n",
    "The input and output of images in opencv is rather easy, with files being easy to read via ```imread()``` and a combination of \n",
    "~~~(Python)\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "imshow('Webcam', frame)\n",
    "~~~\n",
    "suffices to open the webcam and display an image. Further cameras can be accessed by increasing the integer in ```cv2.VideoCapture(0)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('figures/teacher.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow('Teacher', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(1,13):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    plt.subplot(4,3,i)\n",
    "    imshow('Frame' + str(i), frame)\n",
    "cap.release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The images are stored as arrays. Color images are arrays of height x width x 3 (for each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(im[:,:,i])\n",
    "    plt.title(str(i+1))\n",
    "plt.subplot(1,4,4)\n",
    "imshow('1+2+3',im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that it is relatively easy to access only portions of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow('Face',im[500:2400, 800:2000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of course possible to store this sub-image into a new frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = im[500:2400, 800:2000,:]\n",
    "imshow('Face', face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try to show the mouth only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size transformation\n",
    "\n",
    "Using the ```resize()```function, a quick and easy resizing is possible. It accepts a tuple of integer values, in the case at hand ```(int(0.125*w), int(0.125*h))``` to scale the image down to 1/8th of its original size. For this it is handy to use ```im.shape``` to find the original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = im.shape\n",
    "im = cv2.resize(im, (int(0.125*w), int(0.125*h)))\n",
    "imshow('Resized', im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color transformation \n",
    "\n",
    "The standard colorspace in OpenCV is BGR, i.e. Blue-Green-Red. The most common conversion between colorspaces it the transformation from color to black and white:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "imshow('Grayscale', imGray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be further transformed to black and white by thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,imBW = cv2.threshold(imGray,120,255,cv2.THRESH_BINARY)\n",
    "imshow('Black and white', imBW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Experiment with different threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image smoothing\n",
    "\n",
    "It is frequently necessary to smoothen images in order to get rid of too many details, or to pronounce other. A quite common and useful filter is the Gaussian blur, which blur the image by convolution with a 2D-Gaussian distribution. Input parameters are convolution kernel size (have to be odd!) and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imBlur = cv2.GaussianBlur(imGray,(3,3), 1)\n",
    "imshow('Gaussian Blur', imBlur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Experiment with different kernel size and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological operations\n",
    "\n",
    "The presence of a black and white image, containing only 0 and 1 entries, paves the way to morphological operations, i.e. eroding and dilating image values. Erosion, as the name suggests, removes the outer white areas according to a kernel shape and size. Dilation connects white regions and thins out lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "imEr = cv2.erode(imBW,kernel,iterations = 1)\n",
    "imDil = cv2.dilate(imBW,kernel,iterations = 1)\n",
    "plt.subplot(131)\n",
    "imshow('Original', imBW)\n",
    "plt.subplot(132)\n",
    "imshow('Erosion', imEr)\n",
    "plt.subplot(133)\n",
    "imshow('Dilation', imDil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the erosion mostly turns the grayish area above the shoulders black, while dilation mostly removes it. There are many more morphological operations available, however with erosion and dilation, most of tasks can be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try different kernel sizes, also non-symmetric ones and observe the effects. Try to remove the whole face except for the eyebrows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Image gradients\n",
    "\n",
    "A further important concept is the idea of gradients in images, i.e. discrete derivatives between pixels. It is mostly used in a Canny filter, which combines five steps:\n",
    "\n",
    "1. Apply Gaussian filter to smooth the image in order to remove the noise\n",
    "1. Find the intensity gradients of the image using Sobel differentials\n",
    "1. Non-maximum suppression\n",
    "1. Hysteresis thresholding: the pixels with gradients above the upper threshold are sure to be edges, those below the lower bound are sure to be non-edges. Those between are decided based on their connectivity: if they are connected to sure-edge pixels, they are edges, otherwise not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imGrad = cv2.Canny(imGray,100,200)\n",
    "plt.figure(figsize=(8,16))\n",
    "plt.subplot(131)\n",
    "plt.imshow(imGray, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(132)\n",
    "plt.imshow(imGrad, cmap = 'gray')\n",
    "plt.title('Gradient image')\n",
    "plt.subplot(133)\n",
    "plt.imshow(imGray, cmap = 'gray')\n",
    "plt.imshow(imGrad, cmap = 'Reds', alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Line transformation\n",
    "\n",
    "The idea behind Hough Line detection is to rotate the image and sum up the pixel values of all pixels in one direction, effectively transforming the image to its line space as depicted below:\n",
    "\n",
    "![Hough result by Wikimedia/Daf-de](figures/Hough.png)\n",
    "\n",
    "(Image by Wikimedia user Daf-de, CC-BY-SA 3.0)\n",
    "\n",
    "This image clearly show the two maxima for both detected lines. For real world images, it is good to smooth these beforehand.\n",
    "\n",
    "We will use a real world image as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "im = cv2.imread('figures/Ruhrtalbahn.jpg')\n",
    "# Reduce reduce resolution\n",
    "h,w,c = im.shape\n",
    "im = cv2.resize(im, (int(0.25*w), int(0.25*h)))\n",
    "# Cropping: Exclude horizon, square image\n",
    "h,w,c = im.shape\n",
    "im = im[0:w,:,:]\n",
    "h,w,c = im.shape\n",
    "# Convert to gray image\n",
    "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "# Reduce plant edges by smoothing \n",
    "gray = cv2.GaussianBlur(gray,(11,11), 3)\n",
    "# Apply Canny edge detector\n",
    "edges = cv2.Canny(gray,170,220,apertureSize = 3)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(131)\n",
    "imshow('Original cropped', im)\n",
    "plt.subplot(132)\n",
    "imshow('Smoothed', gray)\n",
    "plt.subplot(133)\n",
    "imshow('Edges', edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough Line detector on edges image\n",
    "lines = cv2.HoughLines(edges,5,np.pi/180,200)\n",
    "for rho,theta in lines[:,0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(im,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.figure(figsize=(10,8))    \n",
    "imshow('Ruhrtalbahn', im)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Perspective image transformation\n",
    "\n",
    "We will use the inverse perspective mapping, which maps pixels $(u,v)$ in the image plane to cartesian $(x,y)$ coordinates.\n",
    "\n",
    "This is achieved by help of a transformation mapping\n",
    "$$\\begin{bmatrix}x\\\\y\\\\w' \\end{bmatrix} = \\begin{bmatrix} h_{11} & h_{12} & h_{13} \\\\ h_{21} & h_{22} & h_{23} \\\\ h_{31} & h_{32} & h_{33}\\end{bmatrix} \\begin{bmatrix} u\\\\v\\\\w\\end{bmatrix}$$,\n",
    "\n",
    "for which the OpenCV function ```cv2.getPerspectiveTransform(src,dst)``` can supply a transformation matrix for an array of points. For straight rails, these can be read from the images by matching the bottom $x$ coordinate to the converging coordinate closer to the image horizon.\n",
    "\n",
    "It appropriate to add zero-padding to the images since the remote end will be considerably distorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "im = cv2.imread('figures/Ruhrtalbahn.jpg')\n",
    "# Reduce reduce resolution\n",
    "h,w,c = im.shape\n",
    "im = cv2.resize(im, (int(0.25*w), int(0.25*h)))\n",
    "# Cropping: Exclude horizon, square image\n",
    "h,w,c = im.shape\n",
    "im = im[0:w,:,:]\n",
    "ih,iw,l = im.shape\n",
    "\n",
    "pad = 500\n",
    "imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "impadded = cv2.copyMakeBorder(im, 0, 0, pad, pad, cv2.BORDER_CONSTANT, 0)\n",
    "graypadded = cv2.copyMakeBorder(imgray, 0, 0, pad, pad, cv2.BORDER_CONSTANT, 0)\n",
    "#######################\n",
    "# Birds eye transformation\n",
    "# Points for transformation\n",
    "src = np.float32([[pad+203,ih], [pad+377,400],  [pad+570,ih], [pad+414,400]])\n",
    "dst = np.float32([[pad+203,ih], [pad+203,400],  [pad+570,ih], [pad+570,400]])\n",
    "# Transformation matrix\n",
    "M = cv2.getPerspectiveTransform(src,dst)\n",
    "# Transformation\n",
    "warped = cv2.warpPerspective(impadded, M, (iw+2*pad,ih))\n",
    "# Plotting\n",
    "plt.figure(figsize = (10,20))\n",
    "plt.subplot(131)\n",
    "imshow('Original', im)\n",
    "plt.subplot(1,3,(2,3))\n",
    "imshow('Birds eye view', warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Load the image 'figures/LevelCrossing.png'. Display and inspect it. \n",
    "\n",
    "Apply grayscale filtering, smoothing, edge and line dectection in order to find the rails. Apply birds eye transformation to the image with rail lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
