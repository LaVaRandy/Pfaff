{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silent-board",
   "metadata": {},
   "source": [
    "# Object detection\n",
    "\n",
    "After importing and manipulating images, the detection of objects in these images is a common next step. We will introduce histogram of oriented gradients filter and analytical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV\n",
    "import cv2\n",
    "# Since OpenCV is based on numpy:\n",
    "import numpy as np\n",
    "# Import pyplot (we will need this to plot with the notebook)\n",
    "import matplotlib.pyplot as plt\n",
    "# Helper function to provide plots in true colors in the notebook\n",
    "def imshow(title, im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-glory",
   "metadata": {},
   "source": [
    "## Analytical methods\n",
    "\n",
    "We will try to detect the location and size of a red Sh2-signal, as depicted below:\n",
    "\n",
    "![Muttental](figures/Muttentalbahn.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect image\n",
    "im = cv2.imread('figures/Muttentalbahn.jpg')\n",
    "imshow('Muttentalbahn', im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-prevention",
   "metadata": {},
   "source": [
    "We will try to find it due to its strong red colour, let's inspect the three colour channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,12))\n",
    "plt.subplot(131)\n",
    "plt.imshow(im[:,:,0], cmap = 'jet')\n",
    "plt.title('Blue')\n",
    "plt.subplot(132)\n",
    "plt.imshow(im[:,:,1], cmap = 'jet')\n",
    "plt.title('Green')\n",
    "plt.subplot(133)\n",
    "plt.imshow(im[:,:,2], cmap = 'jet')\n",
    "plt.title('Red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-azerbaijan",
   "metadata": {},
   "source": [
    "Apparently, the red isn't as strong as hoped for, especially the brown rust makes it difficult. However, we can remove parts of the brown by observing that green and red channels look almost the same for the rusty patches, so **Red - Green** may be helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[:,:,2] - im[:,:,1], cmap = 'jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-verification",
   "metadata": {},
   "source": [
    "Indeed, the signal values appear to be between 60 and 90 in the subtracted image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "imRdGn = im[:,:,2] - im[:,:,1]\n",
    "imFilt = 255.0*(imRdGn > 60)*(imRdGn<90)\n",
    "ret,imBW = cv2.threshold(imFilt,250,255,cv2.THRESH_BINARY)\n",
    "plt.imshow(imBW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-booking",
   "metadata": {},
   "source": [
    "The signal is visible, however also plenty of rust on the left side. Morphological operations can be used to remove these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kernel\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "# Twice erosion\n",
    "imBW = cv2.erode(imBW,kernel,iterations = 3)\n",
    "# Twice dilation to restore original size\n",
    "imBW = cv2.dilate(imBW,kernel,iterations = 4)\n",
    "# Plot\n",
    "plt.imshow(imBW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "imBW = np.uint8(imBW)\n",
    "#edges = cv2.Canny(imBW, 100,200)\n",
    "contours, hierarchy= cv2.findContours(imBW, \n",
    "                                      cv2.RETR_LIST, \n",
    "                                      cv2.CHAIN_APPROX_NONE)\n",
    "for c in contours:\n",
    "    accuracy= 0.03 * cv2.arcLength(c, True)\n",
    "    approx= cv2.approxPolyDP(c,accuracy,True)\n",
    "    cv2.drawContours(im, [approx], 0, (255,0,255),5)\n",
    "    cv2.putText(im, 'Sh2', \n",
    "                (c[:,0][:,0].max()+15, c[:,0][:,1].min()+15), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   3, (255,0,255), 4, cv2.LINE_AA)\n",
    "\n",
    "imshow('Detected object',im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-bloom",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try to detect the locomotive to the left in a similar fashion, effectively building a computer vision pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instant-racing",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "\n",
    "After the analytical approach, which has certain drawbacks e.g. under changing lighting conditions, we will find faces in an image using a histogram of oriented gradients (HOG) approach. This is a quite efficient way and is the typical implementation in e.g. smartphone cameras.\n",
    "\n",
    "To load the classifier, which is shipped with OpenCV, it is necessary to provide the full path to the ```load```method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('figures/Winners2019.jpg')\n",
    "h,w,c = im.shape\n",
    "im = cv2.resize(im, (int(0.25*w), int(0.25*h)))\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load('/Users/raphael/opt/anaconda3/envs/opencvjupyter/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "face_cascade.load('/Users/raphael/opt/anaconda3/envs/opencvjupyter/share/opencv4/haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "imshow('Winners', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "imGray = cv2.equalizeHist(imGray)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(imGray, 1.01, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "imFaces = im.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "        imFaces = cv2.rectangle(im, (x, y), (x+w,y+h), (255, 0, 255), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow('Winners', imFaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-conspiracy",
   "metadata": {},
   "source": [
    "This results shows that with object detection, we will mostly obtain false positive (lower left) as well as false negative (front and back).\n",
    "\n",
    "Advantages are the higher robustness against changing environments and the comparably little required data for custom training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-telescope",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The ```detectMultiScale``` method accepts several optional parameters, most notably the detection threshold and the windowStride, currently 1.05 and 10, resepectively. Experiment with these parameters. Can you detect the two missing persons? What happens to your overall detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-distinction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "electric-median",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use the ```haarcascade_fullbody.xm``` classifier to detect people in 'figures/Korea.jpg'.\n",
    "\n",
    "![People](figures/Korea.jpg)\n",
    "\n",
    "How many can you detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-murray",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
